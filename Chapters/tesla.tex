\chapter{Tesla and TRex}

\section{Introduction}

Tesla \cite{tesla} is a declarative strongly typed CEP language that, as some other alternatives, provide a comprehensive set of common operation on events (like filtering and parameterization, composition and pattern detection, negation and aggregation) and allows to control selection policies, time windows and event consumption. However, while the competitors rely on informal documentation that leave room to ambiguities, Tesla's unprecedented characteristic is its aim to a complete semantic specification with TRIO \cite{trio}, a first order temporal logic. This choice improve the reasoning process and empower the model rather than the implementation; it is part of the purpose of the thesis to keep working on this track.
% TODO maybe add a rule example to give an initial hint 

Tesla reference implementation is TRex \cite{trex}, a CEP engine written in C++. It was initially demonstrated using an algorithm called automata-based incremental processing (AIP), which transform each rule in a state machine that is spawned and activated by every incoming event until successful pattern detection or failure; AIP was fundamental to analyze complexity bounds imposed by the language. Later it has been rewritten with column-based delayed processing (CDP) \cite{trex-cuda}, that works accumulating events and processing them in batch as soon a possible trigger is detected; this technique was found to be faster and easier to parallelize and offered the opportunity for a CUDA implementation.

Strangely, while the specification of Tesla's semantic was a central topic of the very first paper, a the time of the writing the syntax was always described informally and through examples. That is a risk of possible misunderstandings in the very foundation of the project, so as first thing in this chapter I will try to define the grammar in a more rigorous and hopefully clear way. Then I will summarize the previous writings about semantic and finally will highlight the ambiguities that aroused after system analysis and team discussion, followed by the clarifications or modifications proposed.

\section{Tesla BNF Grammar}

Backus-Naur Form (BNF) is a notation for context-free grammars that allows to recursively define the composition of every single syntax feature. The components of this kind of writing are terminal symbols, that are simple strings possibly empty ($\epsilon$), and non terminal ones, that are wrapped in angle brackets. Each non terminal is defined in a derivation rule and on the right hand side there will be the non terminal name, while on the left one there will be a sequence of symbols possibly separated by a vertical line ($|$) to imply choice between options.

BNF is also used, in a machine readable form, by parser generators like ANTLR (the one used by the project), so technically there is a definition already, but it had to go through some scarcely documented compromises to avoid parsing ambiguities and to face some practical need. The version presented here instead is meant for human comprehension and as a high level reference, so I will try make it as clear and self explanatory as possible, giving up the irrelevant details needed only for parsing purposes.

\subsection{Rule basic structure}

The outline of a rule is characterized by four main sections: definition of the derivate event, pattern of events, attribute assignment and event consumption.

\begin{bnf*}
\bnfprod{rule}{
    \bnfpn{define} \bnfsp
    \bnfpn{from} \bnfsp
    \bnfpn{where} \bnfsp
    \bnfpn{consuming}
}
\end{bnf*}

\subsection{Details for define}

The definition of a complex event is characterized by the name of the soon to be generated tuple and by a list of attributes names and types.

\begin{bnf*}
\bnfprod{define}{
    \bnfts{define} \bnfsp
    \bnfpn{capital identifier} \bnfsp
    \bnfts{(} \bnfsp
    \bnfpn{attributes} \bnfsp
    \bnfts{)}
}
\end{bnf*}
\begin{bnf*}
\bnfprod{attributes}{
    \bnfpn{attribute} \bnfsp
    \bnfpn{attributes tail} \bnfor
    \bnfes
}\\
\bnfprod{attributes tail}{
    \bnfts{,} \bnfsp
    \bnfpn{attribute} \bnfsp
    \bnfpn{attributes tail} \bnfor
    \bnfes
}\\
\bnfprod{attribute}{
    \bnfpn{lower identifier} \bnfsp
    \bnfts{:} \bnfsp
    \bnfpn{attribute type}
}\\
\bnfprod{attribute type}{
    \bnfts{int} \bnfor
    \bnfts{float} \bnfor
    \bnfts{bool} \bnfor
    \bnfts{string}
}
\end{bnf*}

\subsection{Details for from}

From clause is the core of pattern detection and is made of a sequence of predicates on different events and aggregates.

\begin{bnf*}
\bnfprod{from}{
    \bnfts{from} \bnfsp
    \bnfpn{predicate body} \bnfsp
    \bnfpn{predicates}
}
\end{bnf*}
\begin{bnf*}
\bnfprod{predicates}{
    \bnfts{and} \bnfsp
    \bnfpn{predicate} \bnfsp
    \bnfpn{predicates} \bnfor
    \bnfes
}\\
\bnfprod{predicate}{
    \bnfpn{event} \bnfor
    \bnfpn{aggregate}
}
\end{bnf*}

\subsection{Details for where}

The where section is composed by a set of assignments of the attributes of the soon to be generated event using arbitrary expression over the data processed in the pattern detection phase.

\begin{bnf*}
\bnfprod{where}{
    \bnfts{where} \bnfsp
    \bnfpn{assignments} \bnfor
    \bnfes
}
\end{bnf*}
\begin{bnf*}
\bnfprod{assignments}{
    \bnfpn{assignment} \bnfsp
    \bnfpn{assignments tail}
}\\
\bnfprod{assignments tail}{
    \bnfts{,} \bnfsp
    \bnfpn{assignment} \bnfsp
    \bnfpn{assignments tail} \bnfor
    \bnfes
}\\
\bnfprod{assignment}{
    \bnfpn{lower identifier} \bnfsp
    \bnfts{=} \bnfsp
    \bnfpn{expression}
}
\end{bnf*}

\subsection{Details for consuming}

Consumption policy is simply defined as a list of names of events, that took part in the from clause. 

\begin{bnf*}
\bnfprod{consuming}{
    \bnfts{consuming} \bnfsp
    \bnfpn{capital identifier} \bnfsp
    \bnfpn{capital identifiers} \bnfor
    \bnfes
}
\end{bnf*}

\subsection{Details for predicate body}

The base of a predicate is made by a tuple constrained by a set of boolean expression over current event's data and parameters, possibly followed by an alias definition.

\begin{bnf*}
\bnfprod{predicate body}{
    \bnfpn{constrained tuple} \bnfsp
    \bnfpn{alias}
}\\
\bnfprod{constrained tuple}{
    \bnfpn{capital identifier} \bnfsp
    \bnfts{(} \bnfsp
    \bnfpn{constraints} \bnfsp
    \bnfts{)}
}\\
\bnfprod{constraints}{
    \bnfpn{expression} \bnfsp
    \bnfpn{constraints tail} \bnfor
    \bnfes
}\\
\bnfprod{constraints tail}{
    \bnfts{,} \bnfsp % Different from original papers!
    \bnfpn{expression} \bnfsp
    \bnfpn{constraints tail} \bnfor
    \bnfes
}\\
\bnfprod{alias}{
    \bnfts{as} \bnfsp
    \bnfpn{capital identifier} \bnfor
    \bnfes
}
\end{bnf*}

Note: in this formalization we use commas to separate constraint, opposed to $AND$ as in the original papers, to better distinguish predicates vs. filters composition.

\subsection{Details for event}

An event predicate (except the trigger one that we can see in the $from$ clause) adds to tuple filtering a selection policy chosen between $each, not, first, last$ and constraints about the time window.

\begin{bnf*}
\bnfprod{event}{
    \bnfpn{event selection} \bnfsp
    \bnfpn{predicate body} \bnfsp
    \bnfpn{timing}
}\\
\bnfprod{event selection}{
    \bnfts{each} \bnfor
    \bnfts{not} \bnfor % TODO maybe move in aggregates
    \bnfts{first} \bnfor
    \bnfts{last}
}
\end{bnf*}

\subsection{Details for aggregates}

Tesla has the common aggregators that can be found in DBMS and other CEP engines, but the list could be extended if needed. They are applied on a set of tuples filtered in a similar way to event predicates and the result can be used in an additional constraint for the event pattern.

\begin{bnf*}
\bnfprod{aggregate}{
    \bnfpn{aggregate body} \bnfsp
    \bnfpn{aggregate constraint}
}\\
\bnfprod{aggregate body}{
    \bnfpn{aggregator} \bnfsp
    \bnfts{(} \bnfsp
    \bnfpn{aggregate inner} \bnfsp
    \bnfts{)}
}\\
\bnfprod{aggregate inner}{
    \bnfpn{constrained tuple} \bnfsp
    \bnfpn{attribute selection} \bnfsp
    \bnfpn{timing} \bnfsp
}\\
\bnfprod{aggregator}{
    \bnfts{AVG} \bnfor
    \bnfts{SUM} \bnfor
    \bnfts{MAX} \bnfor
    \bnfts{MIN} \bnfor
    \bnfts{COUNT}
    % TODO maybe add EXISTS/ANY and NOT
}\\
\bnfprod{attribute selection}{
    \bnfts{.} \bnfsp
    \bnfpn{lower identifier} \bnfor
    \bnfes
}\\
\bnfprod{aggregate constraint}{
    \bnfpn{binary operator} \bnfsp
    \bnfpn{expression}
}
\end{bnf*}

\subsection{Details for timing}

Time constraint is imposed with two different type of window: one of given duration from a starting event, the other delimited by a couple of distinct events.

\begin{bnf*}
\bnfprod{timing}{
    \bnfpn{within} \bnfor
    \bnfpn{between}
}\\
\bnfprod{within}{
    \bnfts{within} \bnfsp
    \bnfpn{time} \bnfsp
    \bnfts{from} \bnfsp
    \bnfpn{capital identifier}
}\\
\bnfprod{between}{
    \bnfts{between} \bnfsp
    \bnfpn{capital identifier} \bnfsp
    \bnfts{and} \bnfsp
    \bnfpn{capital identifier}
}\\
\bnfprod{time}{
    \bnfpn{float} \bnfsp
    \bnfpn{time unit} \bnfsp
}\\
\bnfprod{time unit}{
    \bnfts{d} \bnfor
    \bnfts{h} \bnfor
    \bnfts{min} \bnfor
    \bnfts{s} \bnfor
    \bnfts{ms} \bnfor
    \bnfts{us}
}
\end{bnf*}

\subsection{Details for expressions and constraints}

Expressions in Tesla are common algebraic, boolean and string operations composed with each other and they can operate on immediate values, references to current tuple attributes or parameters.

\begin{bnf*}
\bnfprod{expression}{
    \bnfpn{parenthesization} \bnfor
    \bnfpn{operation} \bnfor
	\bnfpn{atom}
}\\
\bnfprod{parenthesization}{
	\bnfts{(} \bnfsp
    \bnfpn{expression} \bnfsp
    \bnfts{)}
}\\
\bnfprod{operation}{
    \bnfpn{binary operation} \bnfor
    \bnfpn{unary operation}
}\\
\bnfprod{binary operation}{
    \bnfpn{expression} \bnfsp
    \bnfpn{binary operator} \bnfsp
    \bnfpn{expression}
}\\
\bnfprod{unary operation}{
    \bnfpn{unary operator} \bnfsp
    \bnfpn{expression}
}\\
\bnfprod{binary operator}{
    \bnftd{Common algebraic and comparison operators}
}\\
\bnfprod{unary operator}{
    \bnftd{Common unary operators}
}\\
\bnfprod{atom}{
    \bnfpn{identifier} \bnfor
    \bnfpn{parameter} \bnfor
    \bnfpn{immediate}
}\\
\bnfprod{identifier}{
	\bnfpn{qualifier} \bnfsp
    \bnfpn{lower identifier}
}\\
\bnfprod{qualifier}{
    \bnfpn{capital identifier} \bnfsp
    \bnfts{.} \bnfor
    \bnfes
}
\end{bnf*}

\subsection{Basic types}

These basic symbols help defining the rest of the BNF. We can notice the three types of identifiers: $capital$ used for event names, $lower$ used for tuple attributes and $parameter$ obviously used for parameterization.

\begin{bnf*}
\bnfprod{capital identifier}{
    \bnftd{An identifier starting with an uppercase letter}
}\\
\bnfprod{lower identifier}{
    \bnftd{An identifier starting with a lowercase letter}
}\\
\bnfprod{parameter}{
    \bnfts{\$} \bnfsp
    \bnfpn{lower identifier}
}\\
\bnfprod{capital identifiers}{
    \bnfts{,} \bnfsp
    \bnfpn{capital identifier} \bnfsp
    \bnfpn{capital identifiers} \bnfor
    \bnfes
}\\
\bnfprod{lower identifiers}{
    \bnfts{,} \bnfsp
    \bnfpn{lower identifier} \bnfsp
    \bnfpn{lower identifiers} \bnfor
    \bnfes
}\\
\bnfprod{immediate}{
    \bnftd{An immediate value, like a digit}
}\\
\bnfprod{float}{
    \bnftd{A floating point number}
}
\end{bnf*}

\section{Semantic}
% TODO summary of semantic as from the previous papers
[...]

\section{Ambiguities and clarifications}

During the analysis of the previously defined syntax, it appeared that there were some ambiguities and that, besides the additions of static data, a renewal of the whole language was appropriate.

\subsection{Parameters}
In previous papers parameterization is presented only through examples and there is no explicit definition of its expressivity. So it isn't clear if parameters are used in some kind of prolog-like logical evaluation or they need two separate phases of assignment and usage.\\
The latter option appear to be the intended one and few more issues follow from that consideration, for example it isn't stated if the order of definition and usage is relevant or binding, there is no difference between assignment and comparison operators and parameters definition is mixed with selection predicates, without any syntax distinction.\\
We need the new syntax to make everything more clear and intuitive by reordering clauses and separating parameters definitions.

\subsection{Event declaration}
Tesla is presented as a strongly typed language and so should be able to protect the system from some incoherences before the actual rule evaluation, but type informations are incomplete and rules can't be checked in advance. Simple events aren't declared beforehand and just appear at runtime as input to the system. Complex event can be emitted by different rules and possibly with different signatures.\\
More over it's impossible to assign a numerical id to an event type for more convenient interaction with external systems.\\
Some of these issues have tackled informally in the implementation, but the solution adopted look more like an unavoidable patch rather than a design choice. To fill those gaps we propose a new independent statement to declare the signature and the id of any event that is going to be processed by the system.

\subsection{Filtering}
The use of the word $WHERE$ for attributes assignment can be counterintuitive, since it wrongly reminds of the $SQL$  clause for rows filtering.\\
Moreover filtering is currently made in the $FROM$ clause, mixed with the selection predicates, in a way that can easily became messy.\\
The new language should improve keywords choice to facilitate the approach of newcomers and it should better separate selection and filtering to keep statements as clean as possible.

\subsection{Timestamp and selection}
During event composition, inclusion or exclusion of a single time instant can make a great difference, but yet it isn't clear if timing intervals should be considered open or closed.\\
In the latter case it would be possible to create paradoxes of events that should be generated if they are not and should be generated if they are, like $define\ A\ from\ B\ and\ not\ A\ within\ X\ from\ B$; at the same time it would be impossible to write a rule like $from\ A\ as\ A1\ and\ not\ A\ within\ X\ from\ A1$ that sounds reasonable at first look, but it wouldn't emit any event.\\
However the former case it wouldn't allow hierarchical and recursive composition, that are needed to modularize when rule complexity increases and to have enough expressivity power to express iteration.
The current implementation, that includes the closest instant and exclude the furthest one, solves the any issue introducing a runtime nondeterminism: it evaluate conditions in execution order and never look back, so different processing order of logically concurrent events could lead to different outcomes.
Since we haven't found a better approach, the procedure will remain the same, but the topic should be discussed again and the users should be aware of the limitations.

\chapter{TESLA and TRex}

\section{Introduction}

TESLA \cite{tesla} is a declarative strongly typed CEP language that, as some other alternatives, provides a comprehensive set of common operation on events (like filtering and parameterization, composition and pattern detection, negation and aggregation) and allows to control selection policies, time windows and event consumption. However, while the competitors rely on informal documentation that leaves room to ambiguities, TESLA's unprecedented characteristic is its aim to a complete semantic specification with TRIO \cite{trio}, a first order temporal logic. The definition in advance of a precise behavior for each feature improves coherence in the development of engines based on TESLA and helps users to understand the language deeply with less empirical research. It is part of the purpose of the thesis to keep working on this track.
% TODO maybe add a rule example to give an initial hint 

TESLA reference implementation is TRex \cite{trex}, a CEP engine written in C++. It was initially designed around an algorithm called automata-based incremental processing (AIP), which transforms each rule in a state machine that is spawned and activated by every incoming event until successful pattern detection or failure; AIP was fundamental to analyze the complexity bounds imposed by the language. Later TRex has been rewritten using a different algorithm called column-based delayed processing (CDP) \cite{trex-cuda}, that works accumulating events and processing them in batch as soon as a possible trigger is detected; this technique was found to be faster and easier to parallelize and offered the opportunity for a CUDA implementation.

While the specification of TESLA's semantic was a central topic of the very first paper, at the time of the writing the syntax was always described informally and through examples. This was identified as a risk of possible misunderstandings in the very foundation of the project, so as first thing in this chapter I will try to define the TESLA grammar in a more rigorous and hopefully clear way. Then I will summarize the previous writings about semantic and finally will highlight the inconsistencies between the semantics of TESLA and its actual implementation in the TRex engine, which aroused after system analysis and team discussion, followed by the clarifications or modifications proposed.

\section{TESLA BNF Grammar}

Backus-Naur Form (BNF) is a notation for context-free grammars that allows to recursively define the composition of every single syntax feature. The components of this kind of writing are terminal symbols, that are simple strings possibly empty ($\epsilon$), and non terminal ones, that are wrapped in angle brackets. Each non terminal is defined in a derivation rule and on the right hand side there will be the non terminal name, while on the left one there will be a sequence of symbols possibly separated by a vertical line ($|$) to imply choice between options.

BNF is also used, in a machine readable form, by parser generators like ANTLR (the one used by the project), so technically there is a definition already, but it had to go through some scarcely documented compromises to avoid parsing ambiguities and to face some practical need. The version presented here instead is meant for human comprehension and as a high level reference, so I will try make it as clear and self explanatory as possible, giving up the irrelevant details needed only for parsing purposes.

\subsection{Rule basic structure}

The outline of a rule is characterized by four main sections: definition of the derivate event, pattern of events, attribute assignment and event consumption.

\begin{bnf*}
\bnfprod{rule}{
    \bnfpn{define} \bnfsp
    \bnfpn{from} \bnfsp
    \bnfpn{where} \bnfsp
    \bnfpn{consuming}
}
\end{bnf*}

\subsection{Details for define}

The definition of a complex event is characterized by the name of the soon to be generated tuple and by a list of attributes names and types.

\begin{bnf*}
\bnfprod{define}{
    \bnfts{define} \bnfsp
    \bnfpn{capital identifier} \bnfsp
    \bnfts{(} \bnfsp
    \bnfpn{attributes} \bnfsp
    \bnfts{)}
}
\end{bnf*}
\begin{bnf*}
\bnfprod{attributes}{
    \bnfpn{attribute} \bnfsp
    \bnfpn{attributes tail} \bnfor
    \bnfes
}\\
\bnfprod{attributes tail}{
    \bnfts{,} \bnfsp
    \bnfpn{attribute} \bnfsp
    \bnfpn{attributes tail} \bnfor
    \bnfes
}\\
\bnfprod{attribute}{
    \bnfpn{lower identifier} \bnfsp
    \bnfts{:} \bnfsp
    \bnfpn{attribute type}
}\\
\bnfprod{attribute type}{
    \bnfts{int} \bnfor
    \bnfts{float} \bnfor
    \bnfts{bool} \bnfor
    \bnfts{string}
}
\end{bnf*}

\subsection{Details for from}

From clause is the core of pattern detection and is made of a sequence of predicates on different events and aggregates.

\begin{bnf*}
\bnfprod{from}{
    \bnfts{from} \bnfsp
    \bnfpn{predicate body} \bnfsp
    \bnfpn{predicates}
}
\end{bnf*}
\begin{bnf*}
\bnfprod{predicates}{
    \bnfts{and} \bnfsp
    \bnfpn{predicate} \bnfsp
    \bnfpn{predicates} \bnfor
    \bnfes
}\\
\bnfprod{predicate}{
    \bnfpn{event} \bnfor
    \bnfpn{aggregate}
}
\end{bnf*}

\subsection{Details for where}

The where section is composed by a set of assignments of the attributes of the soon to be generated event using arbitrary expression over the data processed in the pattern detection phase.

\begin{bnf*}
\bnfprod{where}{
    \bnfts{where} \bnfsp
    \bnfpn{assignments} \bnfor
    \bnfes
}
\end{bnf*}
\begin{bnf*}
\bnfprod{assignments}{
    \bnfpn{assignment} \bnfsp
    \bnfpn{assignments tail}
}\\
\bnfprod{assignments tail}{
    \bnfts{,} \bnfsp
    \bnfpn{assignment} \bnfsp
    \bnfpn{assignments tail} \bnfor
    \bnfes
}\\
\bnfprod{assignment}{
    \bnfpn{lower identifier} \bnfsp
    \bnfts{=} \bnfsp
    \bnfpn{expression}
}
\end{bnf*}

\subsection{Details for consuming}

Consumption policy is simply defined as a list of names of events, that took part in the from clause. 

\begin{bnf*}
\bnfprod{consuming}{
    \bnfts{consuming} \bnfsp
    \bnfpn{capital identifier} \bnfsp
    \bnfpn{capital identifiers} \bnfor
    \bnfes
}
\end{bnf*}

\subsection{Details for predicate body}

The base of a predicate is made by a tuple constrained by a set of boolean expression over current event's data and parameters, possibly followed by an alias definition.

\begin{bnf*}
\bnfprod{predicate body}{
    \bnfpn{constrained tuple} \bnfsp
    \bnfpn{alias}
}\\
\bnfprod{constrained tuple}{
    \bnfpn{capital identifier} \bnfsp
    \bnfts{(} \bnfsp
    \bnfpn{constraints} \bnfsp
    \bnfts{)}
}\\
\bnfprod{constraints}{
    \bnfpn{expression} \bnfsp
    \bnfpn{constraints tail} \bnfor
    \bnfes
}\\
\bnfprod{constraints tail}{
    \bnfts{,} \bnfsp % Different from original papers!
    \bnfpn{expression} \bnfsp
    \bnfpn{constraints tail} \bnfor
    \bnfes
}\\
\bnfprod{alias}{
    \bnfts{as} \bnfsp
    \bnfpn{capital identifier} \bnfor
    \bnfes
}
\end{bnf*}

Note: in this formalization we use commas to separate constraint, opposed to $AND$ as in the original papers, to better distinguish predicates vs. filters composition.

\subsection{Details for event}

An event predicate (except the trigger one that we can see in the $from$ clause) adds to tuple filtering a selection policy chosen between $each, not, first, last$ and constraints about the time window.

\begin{bnf*}
\bnfprod{event}{
    \bnfpn{event selection} \bnfsp
    \bnfpn{predicate body} \bnfsp
    \bnfpn{timing}
}\\
\bnfprod{event selection}{
    \bnfts{each} \bnfor
    \bnfts{not} \bnfor % TODO maybe move in aggregates
    \bnfts{first} \bnfor
    \bnfts{last}
}
\end{bnf*}

\subsection{Details for aggregates}

TESLA has the common aggregators that can be found in DBMS and other CEP engines, but the list could be extended if needed. They are applied on a set of tuples filtered in a similar way to event predicates and the result can be used in an additional constraint for the event pattern.

\begin{bnf*}
\bnfprod{aggregate}{
    \bnfpn{aggregate body} \bnfsp
    \bnfpn{aggregate constraint}
}\\
\bnfprod{aggregate body}{
    \bnfpn{aggregator} \bnfsp
    \bnfts{(} \bnfsp
    \bnfpn{aggregate inner} \bnfsp
    \bnfts{)}
}\\
\bnfprod{aggregate inner}{
    \bnfpn{constrained tuple} \bnfsp
    \bnfpn{attribute selection} \bnfsp
    \bnfpn{timing} \bnfsp
}\\
\bnfprod{aggregator}{
    \bnfts{AVG} \bnfor
    \bnfts{SUM} \bnfor
    \bnfts{MAX} \bnfor
    \bnfts{MIN} \bnfor
    \bnfts{COUNT}
    % TODO maybe add EXISTS/ANY and NOT
}\\
\bnfprod{attribute selection}{
    \bnfts{.} \bnfsp
    \bnfpn{lower identifier} \bnfor
    \bnfes
}\\
\bnfprod{aggregate constraint}{
    \bnfpn{binary operator} \bnfsp
    \bnfpn{expression}
}
\end{bnf*}

\subsection{Details for timing}

Time constraint is imposed with two different type of window: one of given duration from a starting event, the other delimited by a couple of distinct events.

\begin{bnf*}
\bnfprod{timing}{
    \bnfpn{within} \bnfor
    \bnfpn{between}
}\\
\bnfprod{within}{
    \bnfts{within} \bnfsp
    \bnfpn{time} \bnfsp
    \bnfts{from} \bnfsp
    \bnfpn{capital identifier}
}\\
\bnfprod{between}{
    \bnfts{between} \bnfsp
    \bnfpn{capital identifier} \bnfsp
    \bnfts{and} \bnfsp
    \bnfpn{capital identifier}
}\\
\bnfprod{time}{
    \bnfpn{float} \bnfsp
    \bnfpn{time unit} \bnfsp
}\\
\bnfprod{time unit}{
    \bnfts{d} \bnfor
    \bnfts{h} \bnfor
    \bnfts{min} \bnfor
    \bnfts{s} \bnfor
    \bnfts{ms} \bnfor
    \bnfts{us}
}
\end{bnf*}

\subsection{Details for expressions and constraints}

Expressions in TESLA are common algebraic, boolean and string operations composed with each other and they can operate on immediate values, references to current tuple attributes or parameters.

\begin{bnf*}
\bnfprod{expression}{
    \bnfpn{parenthesization} \bnfor
    \bnfpn{operation} \bnfor
	\bnfpn{atom}
}\\
\bnfprod{parenthesization}{
	\bnfts{(} \bnfsp
    \bnfpn{expression} \bnfsp
    \bnfts{)}
}\\
\bnfprod{operation}{
    \bnfpn{binary operation} \bnfor
    \bnfpn{unary operation}
}\\
\bnfprod{binary operation}{
    \bnfpn{expression} \bnfsp
    \bnfpn{binary operator} \bnfsp
    \bnfpn{expression}
}\\
\bnfprod{unary operation}{
    \bnfpn{unary operator} \bnfsp
    \bnfpn{expression}
}\\
\bnfprod{binary operator}{
    \bnftd{Common algebraic and comparison operators}
}\\
\bnfprod{unary operator}{
    \bnftd{Common unary operators}
}\\
\bnfprod{atom}{
    \bnfpn{identifier} \bnfor
    \bnfpn{parameter} \bnfor
    \bnfpn{immediate}
}\\
\bnfprod{identifier}{
	\bnfpn{qualifier} \bnfsp
    \bnfpn{lower identifier}
}\\
\bnfprod{qualifier}{
    \bnfpn{capital identifier} \bnfsp
    \bnfts{.} \bnfor
    \bnfes
}
\end{bnf*}

\subsection{Basic types}

These basic symbols help defining the rest of the BNF. We can notice the three types of identifiers: $capital$ used for event names, $lower$ used for tuple attributes and $parameter$ obviously used for parameterization.

\begin{bnf*}
\bnfprod{capital identifier}{
    \bnftd{An identifier starting with an uppercase letter}
}\\
\bnfprod{lower identifier}{
    \bnftd{An identifier starting with a lowercase letter}
}\\
\bnfprod{parameter}{
    \bnfts{\$} \bnfsp
    \bnfpn{lower identifier}
}\\
\bnfprod{capital identifiers}{
    \bnfts{,} \bnfsp
    \bnfpn{capital identifier} \bnfsp
    \bnfpn{capital identifiers} \bnfor
    \bnfes
}\\
\bnfprod{lower identifiers}{
    \bnfts{,} \bnfsp
    \bnfpn{lower identifier} \bnfsp
    \bnfpn{lower identifiers} \bnfor
    \bnfes
}\\
\bnfprod{immediate}{
    \bnftd{An immediate value, like a digit}
}\\
\bnfprod{float}{
    \bnftd{A floating point number}
}
\end{bnf*}

\section{Semantic}
% TODO summary of semantic as from the previous papers
[...]

\section{Ambiguities and clarifications}

During the analysis of the previously defined syntax, it appeared clear the presence some ambiguities in the semantics of some specific TESLA rules and that, besides the additions of static data, a renewal of the whole language was appropriate.

\subsection{Parameters}
In previous papers parameterization was presented only through examples and there was no explicit definition of its expressivity. So it wasn't clear if parameters needed two separate phases of assignment and usage or they could appear as free variables in high level logical constraints.\\
The former option appeared to be the intended one and few more issues followed from that consideration, for example it wasn't stated if the order of definition and usage was relevant, there was no difference between assignment and comparison operators and parameters definition was mixed with selection predicates, without any syntax distinction.\\
We need the syntax to make everything more clear and intuitive by reordering clauses and separating parameters definitions.

\subsection{Event declaration}
TESLA was presented as a strongly typed language and so it was expected to prevent type incoherences before the actual rule evaluation. However simple events weren't declared beforehand and just appeared at runtime as input to the system, while complex event could be emitted by different rules possibly with different signatures. That lack of information made hard to check in advance.\\
More over it was impossible to assign a numerical id to an event type for more convenient interaction with external systems.\\
Some of these issues have been tackled informally in the implementation, but the solution adopted looked more like an unavoidable patch rather than a design choice. To fill those gaps we propose a new independent statement to declare the signature and the id of any event that is going to be processed by the system.

\subsection{Filtering}
The use of the word $WHERE$ for attributes assignment can be counterintuitive, since it wrongly reminds of the $SQL$  clause for rows filtering.\\
Moreover filtering was made in the $FROM$ clause, mixed with the selection predicates, in a way that could easily became messy.\\
The language revision should improve keywords choice to facilitate the approach of newcomers and it should better separate selection and filtering to keep statements as clean as possible.

\subsection{Timestamp and selection}
During event composition, inclusion or exclusion of the present time instant can make a great difference, but the topic wasn't clearly discussed in previous papers.\\
The exclusion of the present instant wouldn't allow hierarchical and recursive composition, which are needed to modularize rules when complexity increases and to have enough expressivity power to describe iterations.\\
However the choice of closed ranges, which provide that kind of expressivity, would bring some downsides too. For example it would be possible to create paradoxes with events that should be generated if they are not and shouldn't be generated if they are, like:
\begin{align*}
define\ A\ from\ B\ and\ not\ A\ within\ X\ from\ B
\end{align*}
At the same time it would be impossible to write a rule like:
\begin{align*}
define\ B\ from\ A\ as\ A1\ and\ not\ A\ within\ X\ from\ A1
\end{align*}
that sounds reasonable at a first look, but it wouldn't emit any event.\\
A practical solution is the one used by the reference implementation, that includes the closest instant and breaks paradoxes introducing an implicit total ordering: it evaluates conditions in execution order and never looks back. The only price paid is a runtime nondeterminism, which means that different processing order of logically concurrent events could lead to different outcomes.\\
This approach is the most reasonable found so far and should be considered the standard, but the topic should remain open to further discussion.\\

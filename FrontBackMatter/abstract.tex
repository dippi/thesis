%*******************************************************
% Abstract
%*******************************************************
\chapter*{Abstract}
\addcontentsline{toc}{chapter}{\tocEntry{Abstract}}
\markboth{ABSTRACT}{}

Data management systems over the years evolved in two diametrically opposite fields of application: data storage and stream processing. Nowadays both the technologies are widespread and they are often required to cooperate toward a common goal. However the integration of the two is still in an early stage of development and usually custom solutions are required for each specific deployment.

The purpose of the thesis is to model and evaluate a native and general purpose integration of static data sources into the \emph{Complex Event Processing} tool \emph{T-Rex} \cite{trex}. To do so we extended and re-designed the T-Rex engine to integrate a static data source (namely a \emph{SQLite} database) with the event streams that flow into the engine. This required to go through the T-Rex rule language extension, followed by an elaboration of the key algorithms to efficiently process this new language, i.e., to combine static and streaming data, concluding with a careful analysis of the performance of the new engine.


The project shows that events streams and data collections can be modeled with similar logical abstractions, simplifying the description of those problems that operate on the boundary of the two domains. At the same time the real-time performances of the original T-Rex implementation can be preserved, within reasonable limits.

\chapter*{Sommario}
\addcontentsline{toc}{chapter}{\tocEntry{Sommario}}
\markboth{SOMMARIO}{}
I sistemi di data management nel corso degli anni si sono sviluppati in due campi di applicazione diametralmente opposti: immagazzinamento di dati e elaborazione in tempo reale di flussi di informazione. Al giorno d'oggi entrambe le tecnologie sono ampiamente diffuse e spesso è necessario che cooperino per il raggiungimento di comuni obiettivi. Tuttavia l'in\-te\-gra\-zio\-ne delle due è ancora in una fase iniziale di sviluppo e solitamente si rendono necessarie soluzioni personalizzate per specifico caso d'uso.

Lo scopo della tesi è di modellare e validare gli effetti di un'in\-te\-gra\-zio\-ne di sorgenti di dati statici nel tool di \emph{Complex Event Processing} \emph{T-Rex} \cite{trex}. Per raggiungere questo obiettivo presentiamo l'im\-ple\-men\-ta\-zio\-ne di un componente che permetta l'in\-te\-ra\-zio\-ne con un database \emph{SQLite}. In particolare descriviamo l'es\-ten\-sio\-ne del linguaggio di definizione di regole di T-Rex, spieghiamo i principali algoritmi e discutiamo le pre\-sta\-zio\-ni ed i limiti analizzando i risultati di una serie di test.

Il progetto mostra come stream di eventi e collezioni di dati possano in effetti essere descritti con astrazioni logiche del tutto simili, permettendo di affrontare più facilmente problemi che operano sul confine tra i due domini. Inoltre i risultati dei test evidenziano come le prestazioni real-time dell'implementazione originale di T-Rex possano essere preservate sotto ragionevoli condizioni.
